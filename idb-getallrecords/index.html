<!DOCTYPE html>
<style>

</style>

<h1>IndexedDB: getAllRecords()</h1>

<button id="read" disabled>Read in batches</button>
<button id="read-reverse" disabled>Read in reverse order</button>

<script>
  const readButton = document.querySelector("#read");
  const readReverseButton = document.querySelector("#read-reverse");

  // Open the DB.
  const openRequest = indexedDB.open("db", 4);

  // The first time, the onupgradeneeded event is triggered, and we use it
  // to create an object store (similar to a table in SQL databases).
  openRequest.onupgradeneeded = event => {
    console.log("onupgradeneeded");

    const db = openRequest.result

    // Creating an object store.
    console.log("creating user store");
    const store = db.createObjectStore("features");
  };

  function clearStore(db) {
    return new Promise((resolve, reject) => {
      console.log("Creating a transaction to clear the store");
      const clearTransaction = db.transaction("features", "readwrite");

      clearTransaction.oncomplete = event => console.log("Clear transaction complete");
      clearTransaction.onerror = event => {
        console.error("Clear transaction error");
        reject(new Error("Clear transaction error", event));
      };

      // The transaction gives us access to the store, but we need to name it.
      // Indeed, we could have opened the transaction for multiple stores at once.
      const clearTransactionStore = clearTransaction.objectStore("features");

      // We can now clear the store.
      console.log("Clearing the store");
      const clearRequest = clearTransactionStore.clear();

      clearRequest.onsuccess = event => {
        console.log("Store cleared");
        resolve();
      }

      clearRequest.onerror = event => {
        console.error("Error clearing store");
        reject(new Error("Error clearing store", event));
      }
    });
  }

  function addOneFeatureToStore(db, id, name, description) {
    return new Promise((resolve, reject) => {
      console.log("Creating a transaction to add the item to the store");
      const addTransaction = db.transaction("features", "readwrite");

      addTransaction.oncomplete = event => console.log("Add transaction complete");
      addTransaction.onerror = event => {
        console.error("Add transaction error");
        reject(new Error("Add transaction error", event));
      };

      // The transaction gives us access to the store, but we need to name it.
      // Indeed, we could have opened the transaction for multiple stores at once.
      const addTransactionStore = addTransaction.objectStore("features");

      // We can now add data to the store.
      console.log("Adding the data");
      const addRequest = addTransactionStore.add({ name, description }, id);

      addRequest.onsuccess = event => {
        console.log("Data added");
        resolve();
      }

      addRequest.onerror = event => {
        console.error("Error adding data");
        reject(new Error("Error adding data", event));
      }
    });
  }

  async function addAllFeatures(db) {
    // Get some data to populate our store. The data isn't important. We just need to get a lot of it.
    const response = await fetch("./features.json");
    const data = await response.json();

    const featureAdditionPromises = Object.keys(data.features).map(id => {
      const { name, description } = data.features[id];
      return addOneFeatureToStore(db, id, name, description);
    });

    return Promise.all(featureAdditionPromises);
  }

  // Reading a DB in order can be done in mulitple ways.
  // With a cursor, you do it one at a time, which means that if you're reading a
  // lot of records, you will suffer through a lot of back and forth between the
  // main thread and the IDB engine thread.
  // You could also just read the entire DB at once, but if that DB is big, you
  // will have memory problems.
  // Below, we use getAll+getAllKeys to read the DB in batches, limiting the number
  // of back-and-forth with the IDB engine thread.
  // However this doesn't support reading in reverse order, and forces to use both
  // getAll and getAllKeys together. Plus, finding the right batch size might be
  // difficult. 
  async function readInBatches(db) {
    const batchSize = 10;

    console.log("starting read transaction");
    const readTransaction = db.transaction("features", "readonly");

    readTransaction.oncomplete = event => console.log("read transaction complete");
    readTransaction.onerror = event => console.log("read transaction error");

    const readTransactionStore = readTransaction.objectStore("features");

    function getAllKeys(range) {
      return new Promise(resolve => {
        readTransactionStore.getAllKeys(range, batchSize).onsuccess = event => {
          resolve(event.target.result);
        };
      });
    }

    function getAllValues(range) {
      return new Promise(resolve => {
        readTransactionStore.getAll(range, batchSize).onsuccess = event => {
          resolve(event.target.result);
        };
      });
    }

    let range = null;

    while (true) {
      const [keys, values] = await Promise.all([getAllKeys(range), getAllValues(range)]);
      if (keys && values && values.length === batchSize) {
        // There could be more records, set a starting range for next iteration.
        range = IDBKeyRange.lowerBound(keys.at(-1), true);

        console.log(`Read ${batchSize} records`, keys, values);
      } else {
        break;
      }
    }
  }

  // The same code as above, but using the newly proposed getAllRecords method instead.
  // This method is more convenient as it returns both keys and values in a single call.
  async function readInBatches_new(db) {
    const batchSize = 10;

    console.log("starting read transaction");
    const readTransaction = db.transaction("features", "readonly");

    readTransaction.oncomplete = event => console.log("read transaction complete");
    readTransaction.onerror = event => console.log("read transaction error");

    const readTransactionStore = readTransaction.objectStore("features");

    function getNextBatch(lastRecord) {
      return new Promise(resolve => {
        const query = lastRecord ? IDBKeyRange.lowerBound(lastRecord.key, true) : null;
        readTransactionStore.getAllRecords({ query, count: batchSize }).onsuccess = event => {
          resolve(event.target.result);
        };
      });
    }

    let lastRecord = null;
    while (true) {
      const records = await getNextBatch(lastRecord);
      if (records.length === batchSize) {
        lastRecord = records.at(-1);
        console.log(`Read ${batchSize} records`, records);
      } else {
        break;
      }
    }
  }

  // Reading in reserve order requires the use of a cursor.
  // This means that it has to be done one item at a time.
  async function readReverse(db) {
    const batchSize = 10;

    console.log("starting read transaction");
    const readTransaction = db.transaction("features", "readonly");

    readTransaction.oncomplete = event => console.log("read transaction complete");
    readTransaction.onerror = event => console.log("read transaction error");

    const readTransactionStore = readTransaction.objectStore("features");

    readTransactionStore.openCursor(null, "prev").onsuccess = event => {
      const cursor = event.target.result;
      if (cursor) {
        console.log(`Read one item backward`, cursor.key, cursor.value);
        cursor.continue();
      } else {
        console.log("Reverse read done");
      }
    };
  }

  // The same code as above, but using the newly proposed getAllRecords method instead.
  // This method makes it possible to read in batches in reverse order, which is not the
  // case of the previous method, which necessitates using a cursor (one-by-one iteration).
  async function readReverse_new(db) {
    const batchSize = 10;

    console.log("starting read transaction");
    const readTransaction = db.transaction("features", "readonly");

    readTransaction.oncomplete = event => console.log("read transaction complete");
    readTransaction.onerror = event => console.log("read transaction error");

    const readTransactionStore = readTransaction.objectStore("features");

    function getNextBatch(lastRecord) {
      return new Promise(resolve => {
        const query = lastRecord ? IDBKeyRange.upperBound(lastRecord.key, true) : null;
        readTransactionStore.getAllRecords({ query, count: batchSize, direction: "prev" }).onsuccess = event => {
          resolve(event.target.result);
        };
      });
    }

    let lastRecord = null;
    while (true) {
      const records = await getNextBatch(lastRecord);
      if (records.length === batchSize) {
        lastRecord = records.at(-1);
        console.log(`Read ${batchSize} records`, records);
      } else {
        break;
      }
    }
  }

  // Transactions can't run before the onupgradeneeded event has finished.
  // We can wait by using the onsuccess event of the request.
  openRequest.onsuccess = async event => {
    console.log("onsuccess");

    const db = openRequest.result;

    // Start by clearing the entire store
    await clearStore(db);

    // Add some data to the store.
    await addAllFeatures(db);

    readButton.removeAttribute("disabled");
    readButton.addEventListener("click", () => {
      readInBatches(db);
    });

    readReverseButton.removeAttribute("disabled");
    readReverseButton.addEventListener("click", () => {
      readReverse(db);
    });
  };
</script>